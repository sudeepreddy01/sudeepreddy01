# -*- coding: utf-8 -*-
"""predicting employee.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eR9yGeWst9bVV2BtBFVORs6cw9cXyAX7
"""

import numpy as np
import pandas as pd
import seaborn as sns

from google.colab import files
uploaded=files.upload()

dataset=pd.read_csv("WA_Fn-UseC_-HR-Employee-Attrition.csv")
dataset.head()

dataset.shape

dataset.dtypes

dataset.isna().sum()

dataset.isnull().values.any()

dataset.describe()

dataset['Attrition'].value_counts()

sns.countplot(dataset['Attrition'])

import matplotlib.pyplot as plt
plt.subplots(figsize=(12,4))
sns.countplot(x='Age', hue='Attrition', data = dataset, palette="colorblind")

for column in dataset.columns:
    if dataset[column].dtype == object:
        print(str(column) + ' : ' + str(dataset[column].unique()))
        print(dataset[column].value_counts())
        print("_________________________________________________________________")

plt.figure(figsize=(14,14))  #14in by 14in
sns.heatmap(dataset.corr(), annot=True, fmt='.0%')

from sklearn.preprocessing import LabelEncoder

for column in dataset.columns:
        if dataset[column].dtypes == np.int64:
            continue
        dataset[column] = LabelEncoder().fit_transform(dataset[column])

dataset['Age_Years'] = dataset['Age']
#Remove the first column called age 
dataset = dataset.drop('Age', axis = 1)

#Split the data into independent 'X' and dependent 'Y' variables
X = dataset.iloc[:, 1:dataset.shape[1]].values 
Y = dataset.iloc[:, 0].values

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)

from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
forest.fit(X_train, Y_train)

forest.score(X_train, Y_train)

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(Y_test, forest.predict(X_test))
  
TN = cm[0][0]
TP = cm[1][1]
FN = cm[1][0]
FP = cm[0][1]
  
print(cm)
print('Model Testing Accuracy = "{}!"'.format(  (TP + TN) / (TP + TN + FN + FP)))
print()# Print a new line

(1233 - 237)/ 1233

importances = pd.DataFrame({'feature':dataset.iloc[:, 1:dataset.shape[1]].columns,'importance':np.round(forest.feature_importances_,3)}) #Note: The target column is at position 0
importances = importances.sort_values('importance',ascending=False).set_index('feature')
importances

#Visualize the importance
importances.plot.bar()

import pickle
import sklearn

filename='model'
pickle.dump(dataset, open('model.pkl','wb'))